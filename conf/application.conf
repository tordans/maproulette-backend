# This is the main configuration file for the application.
# ~~~~~

# The application languages
# ~~~~~
application.langs="en,af,fr,es"

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Default to Global in the root package.
# application.global=Global

# Router
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point.
# Furthermore, it's assumed your route file is named properly.
# So for an application router like `my.application.Router`,
# you may need to define a router file `conf/my.application.routes`.
# Default to Routes in the root package (and conf/routes)
# application.router=my.application.Routes

# Database configuration
# ~~~~~
# You can declare as many datasources as you want.
# By convention, the default datasource is named `default`
#
db {
  default {
    pool="hikaricp"
    driver="org.postgresql.Driver"
    url="jdbc:postgresql://localhost:5432/mr_prod"
    url=${?MR_DATABASE_URL}

    username="mrdbuser"
    username=${?MR_DATABASE_USERNAME}

    password="mrdbpassword"
    password=${?MR_DATABASE_PASSWORD}

    hikaricp {
      connectionTestQuery="SELECT 1"
      # The database connection pool size can be tweaked based on available system resources and needed throughput.
      # Increasing this value causes parallel database transactions at the cost of more RAM, more CPU.
      # Note:
      #   - The pool size should be less than the total postgres connections. Postgres defaults to 100 connections and more powerful systems tend to allow many more.
      #     - https://www.postgresql.org/docs/current/runtime-config-connection.html
      #   - HikariCP defaults to 10.
      maximumPoolSize = 30
    }
  }
}

akka {
  # Refer to the manual for akka logging options
  # https://doc.akka.io/docs/akka/current/logging.html
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "WARNING"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    provider = "cluster"
    debug {
      # receive = on
      # autoreceive = on
      # lifecycle = on
    }
    # By default Akka uses the CPU core count to determine the number of threads used
    # to service requests. There are endpoints that block due to the JDBC driver not
    # supporting async, and it is suggested to greatly increase the Akka thread count.
    # For more information see the documentation where it has an example of 300 threads:
    # https://www.playframework.com/documentation/2.8.x/ThreadPools#Knowing-when-you-are-blocking
    default-dispatcher {
      executor = fork-join-executor
      fork-join-executor {
        # Number of threads = ceil(NCPU*parallelism-factor), bounded by the below min and max.
        # For example a dual-core system will use a pool with up to 2*32=64 threads.
        parallelism-factor = 32
        parallelism-min = 8
        parallelism-max = 128
        task-peeking-mode = "FIFO"
      }
    }
  }

  remote.artery {
    canonical {
      hostname = "127.0.0.1"
      hostname = ${?MR_AKKA_HOST}
      port = 25520
      port = ${?MR_AKKA_PORT}
    }
  }
}
play {
  evolutions.db.default {
    autoCommit = false
    autoApply = true
    autoApplyDowns = false
  }
  server {
    netty.transport = "native"
    https {
      keyStore {
        # The path to the keystore
        path = ""
        path = ${?https.keyStore}
        # The type of the keystore
        type = "JKS"
        type = ${?https.keyStoreType}
        # The password for the keystore
        password = ""
        password = ${?https.keyStorePassword}
        # The algorithm to use. If not set, uses the platform default algorithm.
        algorithm = ${?https.keyStoreAlgorithm}
      }
      # HTTPS truststore configuration
      trustStore {
        # If true, does not do CA verification on client side certificates
        noCaVerification = false
      }
    }
    ws.timeout.idle=3600s
  }
  # This is the max memory for post body data
  http {
    parser.maxDiskBuffer=15000K
    parser.maxMemoryBuffer=15000K
    filters="org.maproulette.filters.Filters"
    secret.key="%APPLICATION_SECRET%"
    secret.key=${?APPLICATION_SECRET}
    session.sameSite=null
    idleTimeout = 120s
  }
  MultipartFormData.maxLength=15000K
  modules.enabled += "org.maproulette.jobs.JobModule"
  filters {
    enabled += "play.filters.gzip.GzipFilter"
    gzip {
      whiteList = []
    }
    cors {
      // CORS filters options - see https://www.playframework.com/documentation/2.5.x/CorsFilter
      pathPrefixes = ["/"]
      allowedOrigins = null
      allowedHttpMethods = null
      allowedHttpHeaders = null
    }
  }
  ws {
    useragent="MapRoulette"
    #ssl {
    #  loose {
    #    allowWeakCiphers=true
    #    acceptAnyCertificate=true
    #    allowWeakProtocols = true
    #  }
    #  debug.ssl = true
    #}
  }
  # SMTP: see https://github.com/playframework/play-mailer/blob/master/README.md for options
  mailer {
    # host = "your.smtp.server.com"
    # user = "smtpusername"
    # password = "secret"
  }
}

# MapRoulette Settings
maproulette {
  version="2.1.0"
  action.level=1
  #session timeout in milliseconds, default -1 which ignores session timeouts
  session.timeout=-1
  # The protocol://hostname:port of server for use in absolute URLs generated for
  # links in CSV exports, email notifications, etc. E.G. https://myserver.org
  publicOrigin="https://maproulette.org"
  emailFrom="maproulette@example.com"

  # redirect for OSM
  frontend="http://127.0.0.1:3000"

  task {
    # number of days till we reset the status if it has not been fixed
    reset = 14
    changesets {
      timeLimit="1 hour"
      enabled=false
    }

    # The maximum number of tasks per Challenge
    max_tasks_per_challenge=50000
  }
  #logo="/assets/images/companylogo.png"
  signin=false
  debug=false
  devMode=false
  skipTooHard=false
  limits {
    challenges=3
    activities=10
    saved=5
  }
  super {
    # In general the super key should not be enabled, if it is any user with this key can access the system
    # as a super user and have full access to everything. Use with caution.
    key=""
    key=${?MR_SUPER_KEY}
    # This field will give super user access to any osm id that is in this comma seperated list automatically
    # on sign in. If the user has already signed in, the account will be updated in at least a day, or
    # the user can just click the refresh button to get it applied. Removing them from the list will remove
    # their access.
    accounts=""
    accounts=${?MR_SUPER_ACCOUNTS}
  }
  scheduler {
    startTimeJitterForMinuteTasks = "60 seconds"
    startTimeJitterForHourTasks = "60 minutes"

    cleanLocks.interval = "1 hour"
    cleanClaimLocks.interval = "1 hour"
    runChallengeSchedules.interval = "24 hours"
    updateLocations.interval = "2 hours"
    cleanOldTasks {
      interval = "24 hours"
      olderThan = "31 days"
      statusFilter = [0, 3]
    }
    expireTaskReviews {
      interval = "7 days"
      olderThan = "180 days"
    }
    osmMatcher {
      interval = "24 hours"
      batchSize = 5000
      enabled = false
      manual = false
    }
    cleanDeleted.interval = "24 hours"
    keepRight.interval = "7 days"
    challengesLeaderboard.interval = "1 hour"
    countryLeaderboard {
      interval = "24 hours"
      startTime = "04:00:00"  # Run rebuild of Country Leaderboard at 4am local server time.
    }

    archiveChallenges {
      startTime = "23:00:00"
      interval = "24 hours"
      staleTimeInMonths = 6
    }

    updateChallengeCompletionMetrics {
      interval = "20 minutes"
    }

    notifications {
      immediateEmail {
        interval = "1 minute"
        batchSize = 10 # Maximum number of emails to send per run/interval
      }

      countNotificationDaily {
        startTime = "20:10:00"
        interval = "24 hours"
      }

      countNotificationWeekly {
        startTime = "20:20:00"
        interval = "7 days"
      }

      digestEmail {
        startTime = "20:00:00" # 8pm local server time
        interval = "24 hours" # once daily
      }
    }
    userMetricsSnapshot {
      interval = "24 hours"
      startTime = "12:00:00" # Snapshot every day at midnight local time
    }
    challengesSnapshot {
      interval = "7 days"
      startTime = "1:00:00" # Snapshot every week at 1am local time
    }
  }
  mapillary {
    host = "a.mapillary.com"
    clientId = ""
    border = 0.05
  }

  review {
    # Default value for 'needsReview' setting on users
    # 0 - does not need review
    # 1 - review needed (but user can selectively turn off)
    # 2 - review mandatory (review is always required)
    default = 0
  }
  caching {
    type="caffeine"
    type=${?MR_CACHING_TYPE}
    cacheLimit=10000
    cacheExpiry=900
    redis.resetOnStart=false
  }
}

include "keepright.conf"

osm {
  ql {
    provider="https://overpass-api.de/api/interpreter"
    timeout=120
  }
  server="https://www.openstreetmap.org"
  server=${?MR_OSM_SERVER}
  preferences=""
  #OSM OAuth Provider
  userDetails="/api/0.6/user/details"
  requestTokenURL="/oauth/request_token"
  accessTokenURL="/oauth/access_token"
  authorizationURL="/oauth/authorize"
  callbackURL=""
  consumerKey="CHANGE_ME"
  consumerKey=${?MR_OAUTH_CONSUMER_KEY}
  consumerSecret="CHANGE_ME"
  consumerSecret=${?MR_OAUTH_CONSUMER_SECRET}
  # By default, maproulette needs to edit the OSM map and to read/write the user's preferences (write is needed to store the user's api key to OSM).
  # At times the oauth2 scope needs reduced, for example a local dev or staging environment, to avoid accidentally publishing test data to OSM.
  oauth2Scope = "read_prefs write_prefs write_api"
  oauth2Scope = ${?MR_OSM_OAUTH2SCOPE}
}

# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled

api.version="2.0"
